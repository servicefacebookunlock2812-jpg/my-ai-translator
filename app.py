import streamlit as st
from groq import Groq
import edge_tts
import asyncio
import tempfile
import os

# Groq Setup (á€˜á€›á€­á€¯á€›á€²á€· Key á€”á€²á€· Model á€¡á€á€…á€ºá€€á€­á€¯ á€á€±á€á€»á€¬á€‘á€Šá€·á€ºá€‘á€¬á€¸á€•á€«á€á€šá€º)
GROQ_API_KEY = "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"
client = Groq(api_key=GROQ_API_KEY)

st.set_page_config(page_title="Pro Narrator AI", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ Professional Narrator AI Translator")
st.markdown("á€—á€®á€’á€®á€šá€­á€¯á€‘á€²á€€ á€˜á€¬á€á€¬á€…á€€á€¬á€¸á€€á€­á€¯ á€œá€°á€á€¬á€¸á€á€…á€ºá€šá€±á€¬á€€á€ºá€œá€­á€¯ á€á€»á€±á€¬á€™á€½á€±á€·á€…á€½á€¬ á€•á€¼á€”á€ºá€†á€­á€¯á€•á€±á€¸á€•á€«á€á€Šá€ºá‹")

uploaded_file = st.file_uploader("á€—á€®á€’á€®á€šá€­á€¯ (á€á€­á€¯á€·) á€¡á€á€¶á€–á€­á€¯á€„á€º á€á€„á€ºá€•á€±á€¸á€•á€«", type=['mp4', 'mov', 'avi', 'mkv', 'mp3', 'wav'])

if uploaded_file is not None:
    if st.button("á€…á€á€„á€º á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€•á€«"):
        with st.spinner('AI á€€ á€‡á€¬á€á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€±á€¬á€á€°á€á€…á€ºá€šá€±á€¬á€€á€ºá€œá€­á€¯ á€–á€”á€ºá€á€®á€¸á€•á€±á€¸á€”á€±á€•á€«á€á€šá€º...'):
            try:
                # áá‹ á€–á€­á€¯á€„á€ºá€€á€­á€¯ á€šá€¬á€šá€®á€á€­á€™á€ºá€¸á€á€¼á€„á€ºá€¸ (FFmpeg Error á€€á€„á€ºá€¸á€…á€±á€›á€”á€º Cloud á€…á€”á€…á€ºá€á€¯á€¶á€¸á€•á€«á€™á€Šá€º)
                file_ext = os.path.splitext(uploaded_file.name)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tfile:
                    tfile.write(uploaded_file.getbuffer())
                    temp_path = tfile.name

                # á‚á‹ Groq Cloud Whisper á€á€¯á€¶á€¸á€•á€¼á€®á€¸ á€¡á€á€¶á€€á€­á€¯ á€…á€¬á€á€¬á€¸á€•á€¼á€±á€¬á€„á€ºá€¸á€á€¼á€„á€ºá€¸
                # (á€’á€®á€”á€Šá€ºá€¸á€€ á€¡á€á€¶á€™á€›á€á€²á€· Error á€€á€­á€¯ á€€á€»á€­á€”á€ºá€¸á€á€±á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€•á€±á€¸á€•á€«á€á€šá€º)
                st.info("á€¡á€†á€„á€·á€º (á): á€…á€€á€¬á€¸á€œá€¯á€¶á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€á€­á€€á€»á€¡á€±á€¬á€„á€º á€”á€¬á€¸á€‘á€±á€¬á€„á€ºá€”á€±á€•á€«á€á€šá€º...")
                with open(temp_path, "rb") as audio_file:
                    transcription = client.audio.transcriptions.create(
                        file=(temp_path, audio_file.read()),
                        model="whisper-large-v3",
                        response_format="verbose_json",
                    )
                
                original_text = transcription.text.strip()
                detected_lang = transcription.language

                if not original_text:
                    st.error("á€—á€®á€’á€®á€šá€­á€¯á€‘á€²á€™á€¾á€¬ á€¡á€á€¶á€›á€¾á€¬á€™á€á€½á€±á€·á€•á€«á‹")
                else:
                    st.write(f"ğŸ” á€á€­á€›á€¾á€­á€›á€á€±á€¬ á€˜á€¬á€á€¬á€…á€€á€¬á€¸: **{detected_lang.upper()}**")

                    # áƒá‹ Narrator Script á€›á€±á€¸á€á€¼á€„á€ºá€¸ (á€•á€­á€¯á€™á€­á€¯á€á€»á€±á€¬á€™á€½á€±á€·á€á€±á€¬ Prompt á€á€¯á€¶á€¸á€‘á€¬á€¸á€á€Šá€º)
                    st.info("á€¡á€†á€„á€·á€º (á‚): á€‡á€¬á€á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€±á€¬á€Ÿá€”á€ºá€–á€¼á€„á€·á€º á€¡á€á€»á€±á€¬á€á€•á€ºá€”á€±á€•á€«á€á€šá€º...")
                    completion = client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {
                                "role": "system", 
                                "content": "You are a top-tier Burmese documentary narrator. Translate the input into natural, engaging, and professional spoken Burmese narration. Use flowy, human-like language. Avoid formal book Burmese. Output ONLY the Burmese translation."
                            },
                            {"role": "user", "content": f"Translate this {detected_lang} into a smooth Burmese narrator script: {original_text}"}
                        ]
                    )
                    mm_text = completion.choices[0].message.content
                    
                    # á„á‹ á€™á€¼á€”á€ºá€™á€¬ AI á€¡á€á€¶á€‘á€¯á€á€ºá€á€¼á€„á€ºá€¸ (ZawZawNeural á€€ á€¡á€á€»á€±á€¬á€™á€½á€±á€·á€†á€¯á€¶á€¸á€•á€«)
                    st.info("á€¡á€†á€„á€·á€º (áƒ): á€á€˜á€¬á€á€€á€»á€á€±á€¬ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€”á€±á€•á€«á€á€šá€º...")
                    output_audio = "final_narrator.mp3"
                    communicate = edge_tts.Communicate(mm_text, "my-MM-ZawZawNeural")
                    asyncio.run(communicate.save(output_audio))

                    st.success("á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸ á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€•á€«á€á€šá€º!")
                    st.subheader("á€™á€¼á€”á€ºá€™á€¬ Narrator Script")
                    st.text_area("", mm_text, height=250)
                    
                    st.subheader("á€”á€¬á€¸á€‘á€±á€¬á€„á€ºá€›á€”á€º (ZawZaw Voice)")
                    st.audio(output_audio)
                
                os.remove(temp_path)
            except Exception as e:
                st.error(f"Error á€–á€¼á€…á€ºá€á€½á€¬á€¸á€•á€«á€á€šá€º: {str(e)}")
