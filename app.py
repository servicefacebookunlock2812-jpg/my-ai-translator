import streamlit as st
from groq import Groq
import edge_tts
import asyncio
import tempfile
import os

# Groq Setup (Latest Model)
GROQ_API_KEY = "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"
client = Groq(api_key=GROQ_API_KEY)

st.set_page_config(page_title="Pro Narrator AI", page_icon="ğŸ™ï¸")
st.title("ğŸ™ï¸ Professional Narrator AI Translator")

uploaded_file = st.file_uploader("á€—á€®á€’á€®á€šá€­á€¯ á€á€„á€ºá€•á€±á€¸á€•á€«", type=['mp4', 'mov', 'avi', 'mkv'])

if uploaded_file is not None:
    if st.button("á€…á€á€„á€º á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€•á€«"):
        with st.spinner('AI á€€ á€‡á€¬á€á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€±á€¬á€á€°á€á€…á€ºá€šá€±á€¬á€€á€ºá€œá€­á€¯ á€–á€”á€ºá€á€®á€¸á€•á€±á€¸á€”á€±á€•á€«á€á€šá€º...'):
            try:
                # áá‹ á€–á€­á€¯á€„á€ºá€€á€­á€¯ á€šá€¬á€šá€®á€á€­á€™á€ºá€¸á€á€¼á€„á€ºá€¸
                file_ext = os.path.splitext(uploaded_file.name)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tfile:
                    tfile.write(uploaded_file.getbuffer())
                    temp_path = tfile.name

                # á‚á‹ á€¡á€á€¶á€–á€™á€ºá€¸á€á€¼á€„á€ºá€¸ (Whisper-v3 á€€á€­á€¯ á€á€¯á€¶á€¸á€‘á€¬á€¸á€œá€­á€¯á€· Error á€€á€„á€ºá€¸á€•á€«á€á€šá€º)
                st.info("á€¡á€†á€„á€·á€º (á): á€¡á€á€¶á€€á€­á€¯ á€á€­á€€á€»á€¡á€±á€¬á€„á€º á€”á€¬á€¸á€‘á€±á€¬á€„á€ºá€”á€±á€•á€«á€á€šá€º...")
                with open(temp_path, "rb") as audio_file:
                    transcription = client.audio.transcriptions.create(
                        file=(temp_path, audio_file.read()),
                        model="whisper-large-v3",
                        response_format="text",
                    )
                original_text = transcription.strip()

                if not original_text:
                    st.error("á€¡á€á€¶á€–á€™á€ºá€¸á€šá€°á á€™á€›á€•á€«á‹")
                else:
                    # áƒá‹ á€á€»á€±á€¬á€™á€½á€±á€·á€á€±á€¬ Narrator Script á€›á€±á€¸á€á€¼á€„á€ºá€¸
                    st.info("á€¡á€†á€„á€·á€º (á‚): á€‡á€¬á€á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€±á€¬á€Ÿá€”á€ºá€–á€¼á€„á€·á€º á€¡á€á€»á€±á€¬á€á€•á€ºá€”á€±á€•á€«á€á€šá€º...")
                    completion = client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {"role": "system", "content": "You are a professional movie narrator. Translate to natural, engaging, and smooth spoken Burmese speech. Do not use book language. Output only the translation."},
                            {"role": "user", "content": f"Translate this into a smooth narrator script: {original_text}"}
                        ]
                    )
                    mm_text = completion.choices[0].message.content
                    
                    # á„á‹ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€‘á€¯á€á€º (ZawZaw á€¡á€á€¶á€€ á€¡á€•á€®á€•á€¼á€„á€ºá€†á€¯á€¶á€¸á€•á€«)
                    st.info("á€¡á€†á€„á€·á€º (áƒ): á€á€˜á€¬á€á€€á€»á€á€±á€¬ á€¡á€á€¶á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€”á€±á€•á€«á€á€šá€º...")
                    output_audio = "final_narrator.mp3"
                    communicate = edge_tts.Communicate(mm_text, "my-MM-ZawZawNeural")
                    asyncio.run(communicate.save(output_audio))

                    st.success("á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸ á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€•á€«á€á€šá€º!")
                    st.subheader("á€™á€¼á€”á€ºá€™á€¬ Narrator Script")
                    st.write(mm_text)
                    st.audio(output_audio)
                
                os.remove(temp_path)
            except Exception as e:
                st.error(f"Error: {str(e)}")
