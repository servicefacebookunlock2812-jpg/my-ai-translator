import streamlit as st
import whisper
from groq import Groq
import edge_tts
import asyncio
import tempfile
import os
import re
from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
import numpy as np
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
import json

# Groq Setup
GROQ_API_KEY = "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"
client = Groq(api_key=GROQ_API_KEY)

st.set_page_config(page_title="AI Video Dubbing", page_icon="ğŸ¬")
st.title("ğŸ¬ AI Video Dubbing - á€‡á€á€ºá€€á€¬á€¸á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸")
st.markdown("**á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€‡á€¬á€á€ºá€†á€±á€¬á€„á€ºá€¡á€á€¶á€á€½á€±á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€”á€²á€· á€¡á€…á€¬á€¸á€‘á€­á€¯á€¸á€™á€šá€º**")

@st.cache_resource
def load_whisper():
    return whisper.load_model("base")

model = load_whisper()

def extract_audio_segments(video_path, timestamps):
    """Video á€€á€”á€± á€¡á€á€¶á€¡á€•á€­á€¯á€„á€ºá€¸á€œá€±á€¸á€á€½á€±á€‘á€¯á€á€ºá€šá€°"""
    try:
        video = VideoFileClip(video_path)
        audio_segments = []
        
        for i, (start, end, text) in enumerate(timestamps):
            # á€¡á€á€¶á€¡á€•á€­á€¯á€„á€ºá€¸á€œá€±á€¸á€‘á€¯á€á€º
            segment_audio = video.audio.subclip(start, end)
            segment_path = f"temp_segment_{i}.wav"
            segment_audio.write_audiofile(segment_path, verbose=False, logger=None)
            audio_segments.append(segment_path)
        
        video.close()
        return audio_segments
    except Exception as e:
        st.error(f"Audio segment á€‘á€¯á€á€ºá€šá€°á€›á€¬á€á€½á€„á€º error: {str(e)}")
        return None

def create_dubbed_video(original_video_path, burmese_audio_path, output_path="dubbed_video.mp4"):
    """á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€”á€²á€· video á€•á€¼á€”á€ºá€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸"""
    try:
        # Original video á€€á€­á€¯á€–á€½á€„á€·á€º
        video = VideoFileClip(original_video_path)
        
        # á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€€á€­á€¯á€–á€½á€„á€·á€º
        burmese_audio = AudioFileClip(burmese_audio_path)
        
        # Original audio á€€á€­á€¯ mute á€œá€¯á€•á€ºá€•á€¼á€®á€¸ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€‘á€Šá€·á€º
        video = video.without_audio()
        final_video = video.set_audio(burmese_audio)
        
        # Video á€á€­á€™á€ºá€¸á€á€¼á€„á€ºá€¸
        final_video.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            temp_audiofile='temp-audio.m4a',
            remove_temp=True,
            verbose=False,
            logger=None
        )
        
        video.close()
        burmese_audio.close()
        final_video.close()
        
        return output_path
    except Exception as e:
        st.error(f"Dubbed video á€–á€”á€ºá€á€®á€¸á€›á€¬á€á€½á€„á€º error: {str(e)}")
        return None

uploaded_file = st.file_uploader("á€‡á€á€ºá€€á€¬á€¸/á€—á€®á€’á€®á€šá€­á€¯ á€–á€­á€¯á€„á€ºá€á€„á€ºá€•á€±á€¸á€•á€«", 
                                type=['mp4', 'mov', 'avi', 'mkv'])

if uploaded_file is not None:
    st.video(uploaded_file)
    
    if st.button("ğŸ­ á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸á€™á€šá€º (Dubbing)"):
        with st.spinner('á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€¡á€á€¶á€á€½á€±á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€•á€¼á€±á€¬á€„á€ºá€¸á€”á€±á€•á€«á€á€šá€º...'):
            try:
                # áá‹ Temporary file á€á€­á€™á€ºá€¸á€á€¼á€„á€ºá€¸
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
                    tfile.write(uploaded_file.read())
                    video_path = tfile.name
                
                st.info("ğŸ” á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€…á€€á€¬á€¸á€á€¶á€á€½á€±á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€”á€±á€•á€«á€á€šá€º...")
                
                # á‚á‹ Whisper á€”á€²á€· transcription with timestamps
                result = model.transcribe(
                    video_path,
                    language=None,
                    task="transcribe",
                    verbose=False,
                    word_timestamps=True
                )
                
                # áƒá‹ Dialogue segments á€™á€»á€¬á€¸á€›á€šá€°
                dialogues = []
                current_segment = ""
                current_start = 0
                
                for segment in result['segments']:
                    text = segment['text'].strip()
                    start = segment['start']
                    end = segment['end']
                    
                    if text:  # á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€á€²á€·á€¡á€•á€­á€¯á€„á€ºá€¸á€•á€²
                        dialogues.append({
                            'text': text,
                            'start': start,
                            'end': end,
                            'duration': end - start
                        })
                
                st.success(f"âœ… á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€¡á€•á€­á€¯á€„á€ºá€¸ {len(dialogues)} á€•á€­á€¯á€„á€ºá€¸á€á€½á€±á€·á€›á€¾á€­á€•á€¼á€®")
                
                # á„á‹ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸
                st.info("ğŸŒ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€”á€±á€•á€«á€á€šá€º...")
                
                # Dialogue á€á€½á€±á€€á€­á€¯ group á€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸ (context á€¡á€á€½á€€á€º)
                dialogue_texts = [d['text'] for d in dialogues]
                combined_text = "\n\n".join([f"[{i+1}] {text}" for i, text in enumerate(dialogue_texts)])
                
                completion = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {"role": "system", "content": """á€™á€„á€ºá€¸á€€ professional video dubbing translator á€–á€¼á€…á€ºá€á€šá€ºá‹ 
                        á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€‡á€¬á€á€ºá€†á€±á€¬á€„á€ºá€á€½á€±á€•á€¼á€±á€¬á€á€²á€· á€…á€€á€¬á€¸á€á€½á€±á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ dubbing á€œá€¯á€•á€ºá€–á€­á€¯á€· á€•á€¼á€”á€ºá€•á€±á€¸á€›á€™á€šá€ºá‹
                        
                        **Dubbing á€¡á€á€½á€€á€º á€á€á€­á€‘á€¬á€¸á€›á€™á€šá€·á€ºá€¡á€á€»á€€á€ºá€™á€»á€¬á€¸:**
                        1. **Lip sync á€€á€­á€¯á€€á€ºá€Šá€®á€¡á€±á€¬á€„á€º** - á€•á€«á€¸á€…á€•á€ºá€œá€¾á€¯á€•á€ºá€›á€¾á€¬á€¸á€™á€¾á€¯á€”á€²á€· á€œá€­á€¯á€€á€ºá€–á€€á€ºá€¡á€±á€¬á€„á€º
                        2. **á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€á€¶á€á€˜á€¬á€** - á€›á€¯á€•á€ºá€›á€¾á€„á€ºá€‘á€²á€™á€¾á€¬ á€•á€¼á€±á€¬á€á€œá€­á€¯á€•á€¼á€”á€ºá€›á€™á€šá€º
                        3. **á€¡á€¬á€™á€±á€¸á€™á€¾á€¯á€”á€²á€·á€œá€­á€¯á€€á€ºá€–á€€á€º** - á€…á€­á€á€ºá€á€¶á€…á€¬á€¸á€™á€¾á€¯á€•á€±á€«á€ºá€™á€°á€á€Šá€ºá€•á€¼á€®á€¸ á€•á€¼á€”á€ºá€›á€™á€šá€º
                        4. **á€á€­á€¯á€á€±á€¬á€„á€ºá€¸á€•á€¼á€®á€¸á€‘á€­á€›á€±á€¬á€€á€ºá€¡á€±á€¬á€„á€º** - á€¡á€á€¶á€‘á€½á€€á€ºá€á€»á€­á€”á€ºá€”á€²á€· á€€á€­á€¯á€€á€ºá€Šá€®á€¡á€±á€¬á€„á€º
                        
                        **á€•á€¯á€¶á€…á€¶:**
                        á€”á€¶á€•á€«á€á€ºá€á€…á€º á€…á€€á€¬á€¸: [á€™á€°á€›á€„á€ºá€¸ á€¡á€„á€ºá€¹á€‚á€œá€­á€•á€ºá€…á€¬]
                        á€™á€¼á€”á€ºá€™á€¬á€•á€¼á€”á€º: [á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ dubbing version]
                        
                        á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€»á€€á€ºá€á€½á€±á€€á€­á€¯ á€”á€¶á€•á€«á€á€ºá€á€…á€ºá€á€¯á€á€»á€„á€ºá€¸á€…á€®á€¡á€á€­á€¯á€„á€ºá€¸ á€•á€¼á€”á€ºá€•á€±á€¸á€•á€«á‹"""},
                        
                        {"role": "user", "content": f"""á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€‡á€¬á€á€ºá€†á€±á€¬á€„á€ºá€á€½á€±á€•á€¼á€±á€¬á€á€²á€· á€…á€€á€¬á€¸á€á€½á€±á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ dubbing á€¡á€á€½á€€á€º á€•á€¼á€”á€ºá€•á€±á€¸á€•á€«á‹
                        á€á€…á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€á€»á€„á€ºá€¸á€…á€®á€€á€­á€¯ á€á€®á€¸á€á€”á€·á€ºá€•á€¼á€”á€ºá€•á€±á€¸á€•á€«á‹
                        
                        á€‡á€á€ºá€€á€¬á€¸á€…á€€á€¬á€¸á€™á€»á€¬á€¸:
                        {combined_text}
                        
                        á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ dubbing version:"""}
                    ],
                    temperature=0.7,
                    max_tokens=3000
                )
                
                translated_text = completion.choices[0].message.content
                
                # á…á‹ Translated text á€€á€­á€¯ á€á€½á€²á€á€¼á€¬á€¸á€á€¼á€„á€ºá€¸
                burmese_dialogues = []
                lines = translated_text.strip().split('\n')
                
                for line in lines:
                    if ':' in line and ']' in line:
                        # Format: [1] á€™á€¼á€”á€ºá€™á€¬á€•á€¼á€”á€º
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            burmese_dialogues.append(parts[1].strip())
                
                # á†á‹ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€‘á€¯á€á€ºá€á€¼á€„á€ºá€¸ (TTS)
                st.info("ğŸ—£ï¸ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€‘á€¯á€á€ºá€”á€±á€•á€«á€á€šá€º...")
                
                # Dialogue á€á€…á€ºá€á€¯á€á€»á€„á€ºá€¸á€…á€®á€¡á€á€½á€€á€º audio á€‘á€¯á€á€º
                burmese_audio_segments = []
                
                for i, (dialogue, burmese_text) in enumerate(zip(dialogues, burmese_dialogues)):
                    if i < len(burmese_dialogues):
                        try:
                            # TTS for each dialogue
                            output_segment = f"burmese_segment_{i}.mp3"
                            
                            # Adjust speech rate based on original duration
                            original_duration = dialogue['duration']
                            expected_words = len(burmese_text.split())
                            
                            # Calculate speech rate
                            if original_duration > 0:
                                words_per_second = expected_words / original_duration
                                rate_adjustment = "+0%"
                                if words_per_second > 3:
                                    rate_adjustment = "+15%"
                                elif words_per_second < 2:
                                    rate_adjustment = "-10%"
                            else:
                                rate_adjustment = "+0%"
                            
                            communicate = edge_tts.Communicate(
                                text=burmese_text,
                                voice="my-MM-ThihaNeural",
                                rate=rate_adjustment,
                                pitch="+0Hz"
                            )
                            
                            asyncio.run(communicate.save(output_segment))
                            burmese_audio_segments.append(output_segment)
                            
                        except Exception as e:
                            st.warning(f"Segment {i+1} á€¡á€á€¶á€‘á€¯á€á€ºá€›á€¬á€á€½á€„á€º á€¡á€á€€á€ºá€¡á€á€²á€›á€¾á€­: {str(e)}")
                
                # á‡á‹ Audio segments á€™á€»á€¬á€¸á€€á€­á€¯ á€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€á€¼á€„á€ºá€¸
                if burmese_audio_segments:
                    st.info("ğŸ”Š á€¡á€á€¶á€¡á€•á€­á€¯á€„á€ºá€¸á€á€½á€±á€€á€­á€¯ á€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€”á€±á€•á€«á€á€šá€º...")
                    
                    # Create combined audio with original timing
                    final_audio = AudioSegment.silent(duration=int(dialogues[-1]['end'] * 1000))
                    
                    for i, (dialogue, audio_segment) in enumerate(zip(dialogues, burmese_audio_segments)):
                        if os.path.exists(audio_segment):
                            segment_audio = AudioSegment.from_mp3(audio_segment)
                            
                            # Adjust to fit original timing if needed
                            target_duration = int(dialogue['duration'] * 1000)
                            current_duration = len(segment_audio)
                            
                            if current_duration > target_duration:
                                # Speed up slightly
                                segment_audio = segment_audio.speedup(playback_speed=current_duration/target_duration)
                            elif current_duration < target_duration:
                                # Add silence at the end
                                silence_needed = target_duration - current_duration
                                silence = AudioSegment.silent(duration=silence_needed)
                                segment_audio = segment_audio + silence
                            
                            # Overlay at correct timing
                            start_ms = int(dialogue['start'] * 1000)
                            final_audio = final_audio.overlay(segment_audio, position=start_ms)
                    
                    # Save final dubbed audio
                    final_audio_path = "final_burmese_audio.wav"
                    final_audio.export(final_audio_path, format="wav")
                    
                    # áˆá‹ Dubbed video á€–á€”á€ºá€á€®á€¸á€á€¼á€„á€ºá€¸
                    st.info("ğŸ¬ Dubbed video á€–á€”á€ºá€á€®á€¸á€”á€±á€•á€«á€á€šá€º...")
                    
                    dubbed_video_path = create_dubbed_video(video_path, final_audio_path)
                    
                    if dubbed_video_path and os.path.exists(dubbed_video_path):
                        st.success("âœ… Dubbing á€•á€¼á€®á€¸á€•á€«á€•á€¼á€®!")
                        
                        # Show results
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader("ğŸ­ á€™á€°á€›á€„á€ºá€¸á€…á€€á€¬á€¸á€™á€»á€¬á€¸")
                            for i, dialogue in enumerate(dialogues[:5]):  # Show first 5
                                st.write(f"{i+1}. [{dialogue['start']:.1f}s-{dialogue['end']:.1f}s]: {dialogue['text']}")
                        
                        with col2:
                            st.subheader("ğŸ‡²ğŸ‡² á€™á€¼á€”á€ºá€™á€¬á€•á€¼á€”á€ºá€™á€»á€¬á€¸")
                            for i, text in enumerate(burmese_dialogues[:5]):
                                st.write(f"{i+1}. {text}")
                        
                        st.subheader("ğŸ”Š á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€¥á€•á€™á€¬")
                        st.audio(final_audio_path, format="audio/wav")
                        
                        st.subheader("ğŸ¬ Dubbed Video Preview")
                        st.video(dubbed_video_path)
                        
                        # Download buttons
                        col3, col4 = st.columns(2)
                        
                        with col3:
                            with open(final_audio_path, "rb") as f:
                                st.download_button(
                                    label="ğŸ“¥ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€–á€­á€¯á€„á€º",
                                    data=f,
                                    file_name="movie_dubbing_audio.wav",
                                    mime="audio/wav"
                                )
                        
                        with col4:
                            with open(dubbed_video_path, "rb") as f:
                                st.download_button(
                                    label="ğŸ“¥ Dubbed Video",
                                    data=f,
                                    file_name="movie_burmese_dubbed.mp4",
                                    mime="video/mp4"
                                )
                        
                        # Cleanup
                        for segment in burmese_audio_segments:
                            if os.path.exists(segment):
                                os.remove(segment)
                        if os.path.exists(final_audio_path):
                            os.remove(final_audio_path)
                        if os.path.exists(dubbed_video_path):
                            os.remove(dubbed_video_path)
                
                # Clean original temp file
                if os.path.exists(video_path):
                    os.remove(video_path)
                    
            except Exception as e:
                st.error(f"âŒ Dubbing process á€™á€¾á€¬ error: {str(e)}")
                import traceback
                st.code(traceback.format_exc())

st.markdown("---")
st.markdown("""
### ğŸ¯ Dubbing System Features:
1. **á€œá€°á€•á€¼á€±á€¬á€á€¶á€€á€­á€¯ detect** - Whisper á€”á€²á€· á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€¡á€•á€­á€¯á€„á€ºá€¸á€á€½á€±á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€º
2. **Timing sync** - á€™á€°á€›á€„á€ºá€¸á€¡á€á€»á€­á€”á€ºá€”á€²á€· á€€á€­á€¯á€€á€ºá€Šá€®á€¡á€±á€¬á€„á€º
3. **Context-aware translation** - á€‡á€á€ºá€œá€™á€ºá€¸á€¡á€œá€­á€¯á€€á€º á€•á€¼á€”á€ºá€†á€­á€¯
4. **Lip-sync attempt** - á€•á€«á€¸á€…á€•á€ºá€œá€¾á€¯á€•á€ºá€›á€¾á€¬á€¸á€™á€¾á€¯á€”á€²á€· á€”á€®á€¸á€…á€•á€ºá€¡á€±á€¬á€„á€º

### âš ï¸ Limitations:
- Perfect lip-sync á€¡á€á€½á€€á€º AI voice cloning á€œá€­á€¯á€¡á€•á€ºá€á€šá€º
- Background music/sounds á€€á€­á€¯ preserve á€œá€¯á€•á€ºá€–á€­á€¯á€· á€•á€­á€¯á€¡á€†á€„á€·á€ºá€™á€¼á€„á€·á€ºá€á€šá€º
- Multiple speakers á€¡á€á€½á€€á€º á€á€½á€²á€á€¼á€¬á€¸á€–á€­á€¯á€·á€œá€­á€¯á€á€šá€º
""")
