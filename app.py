import streamlit as st
import whisper
from groq import Groq
import edge_tts
import asyncio
import tempfile
import os
import re
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
import subprocess

# Groq Setup
GROQ_API_KEY = "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"
client = Groq(api_key=GROQ_API_KEY)

st.set_page_config(page_title="AI Video Dubbing", page_icon="ğŸ¬")
st.title("ğŸ¬ AI Video Dubbing - á€‡á€á€ºá€€á€¬á€¸á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸")
st.markdown("**á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€‡á€¬á€á€ºá€†á€±á€¬á€„á€ºá€¡á€á€¶á€á€½á€±á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€”á€²á€· á€¡á€…á€¬á€¸á€‘á€­á€¯á€¸á€•á€±á€¸á€™á€šá€º**")

@st.cache_resource
def load_whisper():
    return whisper.load_model("base")

model = load_whisper()

def extract_audio_from_video(video_path, audio_output="extracted_audio.wav"):
    """FFmpeg á€á€¯á€¶á€¸á€•á€¼á€®á€¸ video á€€á€”á€± audio á€‘á€¯á€á€ºá€šá€°"""
    try:
        cmd = [
            'ffmpeg', '-i', video_path,
            '-q:a', '0', '-map', 'a',
            '-y', audio_output
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            return audio_output
        else:
            # Alternative method using pydub if ffmpeg not available
            st.warning("FFmpeg á€™á€á€½á€±á€·á€•á€«á‹ á€¡á€á€¼á€¬á€¸á€”á€Šá€ºá€¸á€œá€™á€ºá€¸á€–á€¼á€„á€·á€º á€†á€€á€ºá€œá€¯á€•á€ºá€•á€«á€™á€Šá€ºá‹")
            return None
    except Exception as e:
        st.warning(f"FFmpeg error: {str(e)}")
        return None

def create_sync_burmese_audio(original_audio_path, translated_text, timestamps):
    """á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€€á€­á€¯ sync á€œá€¯á€•á€ºá€•á€¼á€®á€¸ á€‘á€¯á€á€ºá€•á€±á€¸á€á€¼á€„á€ºá€¸"""
    try:
        # Load original audio to get duration
        original_audio = AudioSegment.from_file(original_audio_path)
        
        # Create silent audio of same length
        silent_audio = AudioSegment.silent(duration=len(original_audio))
        
        # Generate Burmese TTS
        tts_output = "burmese_tts_temp.mp3"
        communicate = edge_tts.Communicate(
            text=translated_text,
            voice="my-MM-ThihaNeural",
            rate="+5%",
            pitch="+1Hz"
        )
        asyncio.run(communicate.save(tts_output))
        
        burmese_audio = AudioSegment.from_mp3(tts_output)
        
        # For simplicity, we'll just overlay the burmese audio
        # In production, you'd need to split by timestamps
        final_audio = original_audio.overlay(burmese_audio)
        
        # Save final audio
        final_output = "synced_burmese_audio.wav"
        final_audio.export(final_output, format="wav")
        
        # Cleanup
        if os.path.exists(tts_output):
            os.remove(tts_output)
            
        return final_output
        
    except Exception as e:
        st.error(f"Audio sync error: {str(e)}")
        return None

# Streamlit UI
uploaded_file = st.file_uploader("á€‡á€á€ºá€€á€¬á€¸/á€—á€®á€’á€®á€šá€­á€¯ á€–á€­á€¯á€„á€ºá€á€„á€ºá€•á€±á€¸á€•á€«", 
                                type=['mp4', 'mov', 'avi', 'mkv', 'mp3', 'wav'])

if uploaded_file is not None:
    # Show video preview
    file_ext = uploaded_file.name.split('.')[-1].lower()
    if file_ext in ['mp4', 'mov', 'avi', 'mkv']:
        st.video(uploaded_file)
    else:
        st.audio(uploaded_file)
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ¤ á€…á€€á€¬á€¸á€á€¶á€™á€»á€¬á€¸á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€™á€šá€º"):
            with st.spinner('á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€…á€€á€¬á€¸á€á€¶á€á€½á€±á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€”á€±á€•á€«á€á€šá€º...'):
                try:
                    # Save uploaded file
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_ext}") as tfile:
                        tfile.write(uploaded_file.read())
                        media_path = tfile.name
                    
                    # Extract audio if video
                    audio_path = None
                    if file_ext in ['mp4', 'mov', 'avi', 'mkv']:
                        audio_path = "temp_audio.wav"
                        # Simple audio extraction using pydub
                        try:
                            from pydub import AudioSegment
                            video = AudioSegment.from_file(media_path)
                            video.export(audio_path, format="wav")
                        except:
                            # Fallback: use the original file if audio extraction fails
                            audio_path = media_path
                    else:
                        audio_path = media_path
                    
                    # Transcribe
                    result = model.transcribe(
                        audio_path,
                        language=None,
                        task="transcribe",
                        verbose=False
                    )
                    
                    # Store in session state
                    st.session_state['original_text'] = result['text']
                    st.session_state['segments'] = result.get('segments', [])
                    st.session_state['media_path'] = media_path
                    st.session_state['audio_path'] = audio_path
                    
                    # Show results
                    st.success(f"âœ… á€…á€€á€¬á€¸á€•á€¼á€±á€¬á€¡á€•á€­á€¯á€„á€ºá€¸ {len(result.get('segments', []))} á€•á€­á€¯á€„á€ºá€¸á€á€½á€±á€·á€›á€¾á€­á€•á€¼á€®")
                    
                    with st.expander("ğŸ” á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€‘á€¬á€¸á€á€±á€¬ á€…á€€á€¬á€¸á€á€¶á€™á€»á€¬á€¸"):
                        for i, segment in enumerate(result.get('segments', [])[:10]):  # Show first 10
                            st.write(f"{i+1}. [{segment['start']:.1f}s-{segment['end']:.1f}s]: {segment['text']}")
                    
                except Exception as e:
                    st.error(f"Error: {str(e)}")
    
    with col2:
        if st.button("ğŸ‡²ğŸ‡² á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸á€™á€šá€º"):
            if 'original_text' not in st.session_state:
                st.warning("á€€á€»á€±á€¸á€‡á€°á€¸á€•á€¼á€¯á á€…á€€á€¬á€¸á€á€¶á€™á€»á€¬á€¸á€€á€­á€¯ á€¡á€›á€„á€ºá€–á€±á€¬á€ºá€‘á€¯á€á€ºá€•á€«")
            else:
                with st.spinner('á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€•á€¼á€®á€¸ á€¡á€á€¶á€‘á€¯á€á€ºá€”á€±á€•á€«á€á€šá€º...'):
                    try:
                        # Translate to Burmese
                        original_text = st.session_state['original_text']
                        
                        completion = client.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=[
                                {"role": "system", "content": """á€™á€„á€ºá€¸á€€ á€›á€¯á€•á€ºá€›á€¾á€„á€ºá€’á€«á€›á€­á€¯á€€á€ºá€á€¬á€”á€²á€· á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€†á€›á€¬á€–á€¼á€…á€ºá€á€šá€ºá‹ 
                                á€‡á€á€ºá€€á€¬á€¸á€‘á€²á€€ á€‡á€¬á€á€ºá€†á€±á€¬á€„á€ºá€á€½á€±á€•á€¼á€±á€¬á€á€²á€· á€…á€€á€¬á€¸á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ dubbing á€¡á€á€½á€€á€º á€•á€¼á€”á€ºá€•á€±á€¸á€›á€™á€šá€ºá‹
                                
                                á€á€á€­á€‘á€¬á€¸á€›á€™á€¾á€¬á€á€½á€±:
                                1. á€›á€¯á€•á€ºá€›á€¾á€„á€ºá€‘á€²á€™á€¾á€¬ á€•á€¼á€±á€¬á€á€œá€­á€¯ á€á€˜á€¬á€á€€á€»á€€á€»á€•á€¼á€”á€ºá€•á€«
                                2. á€¡á€á€­á€¯á€á€»á€¯á€¶á€¸á€•á€¼á€®á€¸ á€‘á€­á€›á€±á€¬á€€á€ºá€¡á€±á€¬á€„á€ºá€•á€¼á€”á€ºá€•á€«
                                3. á€™á€¼á€”á€ºá€™á€¬á€•á€›á€­á€á€á€ºá€”á€¬á€¸á€œá€Šá€ºá€¡á€±á€¬á€„á€º á€•á€¼á€”á€ºá€•á€«"""},
                                {"role": "user", "content": f"á€’á€®á€…á€€á€¬á€¸á€€á€­á€¯ á€™á€¼á€”á€ºá€™á€¬á€›á€¯á€•á€ºá€›á€¾á€„á€º dubbing á€¡á€á€½á€€á€º á€•á€¼á€”á€ºá€•á€±á€¸á€•á€«: {original_text}"}
                            ],
                            temperature=0.7,
                            max_tokens=2000
                        )
                        
                        translated_text = completion.choices[0].message.content
                        
                        # Store in session state
                        st.session_state['translated_text'] = translated_text
                        
                        # Generate Burmese TTS
                        output_audio = "burmese_dubbing.mp3"
                        communicate = edge_tts.Communicate(
                            translated_text,
                            "my-MM-ThihaNeural",
                            rate="+5%",
                            pitch="+1Hz"
                        )
                        asyncio.run(communicate.save(output_audio))
                        
                        # Show results
                        st.success("âœ… á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€®á€¸á€•á€«á€•á€¼á€®!")
                        
                        col_a, col_b = st.columns(2)
                        
                        with col_a:
                            st.subheader("á€™á€°á€›á€„á€ºá€¸á€…á€€á€¬á€¸")
                            st.text_area("Original", original_text[:500] + "..." if len(original_text) > 500 else original_text, 
                                       height=200, label_visibility="collapsed")
                        
                        with col_b:
                            st.subheader("á€™á€¼á€”á€ºá€™á€¬á€•á€¼á€”á€º")
                            st.text_area("Translated", translated_text[:500] + "..." if len(translated_text) > 500 else translated_text,
                                       height=200, label_visibility="collapsed")
                        
                        st.subheader("ğŸ”Š á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶ (Dubbing)")
                        st.audio(output_audio)
                        
                        # Download buttons
                        st.download_button(
                            label="ğŸ“¥ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€–á€­á€¯á€„á€ºá€›á€šá€°á€›á€”á€º",
                            data=open(output_audio, "rb"),
                            file_name="movie_dubbing_burmese.mp3",
                            mime="audio/mp3"
                        )
                        
                        # Cleanup
                        if os.path.exists(output_audio):
                            os.remove(output_audio)
                        if 'media_path' in st.session_state and os.path.exists(st.session_state['media_path']):
                            os.remove(st.session_state['media_path'])
                        if 'audio_path' in st.session_state and os.path.exists(st.session_state['audio_path']):
                            os.remove(st.session_state['audio_path'])
                            
                    except Exception as e:
                        st.error(f"Translation/Audio error: {str(e)}")

# Instructions
st.markdown("---")
st.markdown("""
### ğŸ“‹ á€Šá€½á€¾á€”á€ºá€€á€¼á€¬á€¸á€á€»á€€á€ºá€™á€»á€¬á€¸:

**á€•á€‘á€™á€¡á€†á€„á€·á€º:** "ğŸ¤ á€…á€€á€¬á€¸á€á€¶á€™á€»á€¬á€¸á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€™á€šá€º" á€€á€­á€¯á€”á€¾á€­á€•á€ºá€•á€«
**á€’á€¯á€á€­á€šá€¡á€†á€„á€·á€º:** "ğŸ‡²ğŸ‡² á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ á€¡á€á€¶á€•á€¼á€±á€¬á€„á€ºá€¸á€™á€šá€º" á€€á€­á€¯á€”á€¾á€­á€•á€ºá€•á€«

### âš ï¸ á€á€á€­á€•á€¼á€¯á€›á€”á€º:
1. **á€¡á€á€¶á€›á€¾á€„á€ºá€¸á€á€±á€¬ á€—á€®á€’á€®á€šá€­á€¯á€™á€»á€¬á€¸á€€á€­á€¯á€á€¬ á€¡á€á€¯á€¶á€¸á€•á€¼á€¯á€•á€«**
2. **á€á€…á€ºá€€á€¼á€­á€™á€ºá€œá€»á€¾á€„á€º á… á€™á€­á€”á€…á€ºá€‘á€€á€º á€™á€•á€­á€¯á€…á€±á€›**
3. **á€¡á€„á€ºá€á€¬á€”á€€á€ºá€¡á€†á€„á€ºá€•á€¼á€±á€›á€”á€º á€œá€­á€¯á€¡á€•á€ºá€•á€«á€á€Šá€º**

### ğŸ› ï¸ Requirements á€™á€»á€¬á€¸á€‘á€Šá€·á€ºá€›á€”á€º:
```bash
pip install streamlit openai-whisper groq edge-tts pydub
