import streamlit as st
from groq import Groq
import edge_tts
import asyncio
import tempfile
import os

# Groq Setup
GROQ_API_KEY = "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"
client = Groq(api_key=GROQ_API_KEY)

st.set_page_config(page_title="Ultra AI Translator", page_icon="ğŸ¬")
st.title("ğŸ¬ Ultra Fast AI Video Translator")

uploaded_file = st.file_uploader("á€—á€®á€’á€®á€šá€­á€¯ á€á€„á€ºá€•á€±á€¸á€•á€«", type=['mp4', 'mov', 'avi', 'mkv', 'mp3', 'wav'])

if uploaded_file is not None:
    if st.button("á€…á€á€„á€º á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€•á€«"):
        with st.spinner('Cloud AI á€€ á€¡á€á€¶á€€á€­á€¯ á€–á€™á€ºá€¸á€šá€° á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€”á€±á€•á€«á€á€šá€º...'):
            try:
                # áá‹ á€–á€­á€¯á€„á€ºá€€á€­á€¯ á€šá€¬á€šá€®á€á€­á€™á€ºá€¸á€á€¼á€„á€ºá€¸
                suffix = os.path.splitext(uploaded_file.name)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tfile:
                    tfile.write(uploaded_file.getbuffer())
                    file_path = tfile.name

                # á‚á‹ Groq Cloud Whisper á€á€¯á€¶á€¸á€•á€¼á€®á€¸ á€¡á€á€¶á€€á€­á€¯ á€…á€¬á€á€¬á€¸á€•á€¼á€±á€¬á€„á€ºá€¸á€á€¼á€„á€ºá€¸ (á€’á€«á€€ FFmpeg á€™á€œá€­á€¯á€•á€«á€˜á€°á€¸)
                st.info("á€¡á€†á€„á€·á€º (á): á€…á€€á€¬á€¸á€œá€¯á€¶á€¸á€™á€»á€¬á€¸á€€á€­á€¯ á€á€­á€€á€»á€¡á€±á€¬á€„á€º á€”á€¬á€¸á€‘á€±á€¬á€„á€ºá€”á€±á€•á€«á€á€šá€º...")
                with open(file_path, "rb") as file:
                    transcription = client.audio.transcriptions.create(
                        file=(file_path, file.read()),
                        model="distil-whisper-large-v3-en", # á€¡á€œá€½á€”á€ºá€™á€¼á€”á€ºá€á€±á€¬ model
                        response_format="text",
                    )
                original_text = transcription.strip()

                if not original_text:
                    st.error("á€¡á€á€¶ á€›á€¾á€¬á€™á€á€½á€±á€·á€•á€«á€˜á€°á€¸á‹")
                else:
                    # áƒá‹ Groq Llama 3.3 á€”á€²á€· á€á€»á€±á€¬á€™á€½á€±á€·á€¡á€±á€¬á€„á€º á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸
                    st.info("á€¡á€†á€„á€·á€º (á‚): á€œá€°á€á€¬á€¸á€á€…á€ºá€šá€±á€¬á€€á€ºá€œá€­á€¯ á€•á€®á€•á€®á€á€ á€¡á€á€»á€±á€¬á€á€•á€ºá€•á€±á€¸á€”á€±á€•á€«á€á€šá€º...")
                    completion = client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {"role": "system", "content": "You are a professional Burmese storyteller. Translate the text into natural, smooth, spoken Burmese. Only provide the translation."},
                            {"role": "user", "content": f"Translate this: {original_text}"}
                        ]
                    )
                    mm_text = completion.choices[0].message.content
                    
                    # á„á‹ á€™á€¼á€”á€ºá€™á€¬ AI á€¡á€á€¶á€‘á€¯á€á€ºá€á€¼á€„á€ºá€¸
                    st.info("á€¡á€†á€„á€·á€º (áƒ): á€á€˜á€¬á€á€€á€»á€á€±á€¬ á€™á€¼á€”á€ºá€™á€¬á€¡á€á€¶á€€á€­á€¯ á€–á€”á€ºá€á€®á€¸á€”á€±á€•á€«á€á€šá€º...")
                    output_audio = "final_voice.mp3"
                    communicate = edge_tts.Communicate(mm_text, "my-MM-ZawZawNeural")
                    asyncio.run(communicate.save(output_audio))

                    st.success("á€˜á€¬á€á€¬á€•á€¼á€”á€ºá€á€¼á€„á€ºá€¸ á€¡á€±á€¬á€„á€ºá€™á€¼á€„á€ºá€•á€«á€á€šá€º!")
                    st.subheader("á€™á€¼á€”á€ºá€™á€¬ Script")
                    st.write(mm_text)
                    st.audio(output_audio)
                
                os.remove(file_path)
            except Exception as e:
                st.error(f"Error: {str(e)}")
